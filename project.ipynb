{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, resnet18, squeezenet1_1\n",
    "from torchvision.models.resnet import ResNet50_Weights, ResNet18_Weights\n",
    "from torchvision.models import efficientnet_v2_l\n",
    "from torchvision.models.efficientnet import EfficientNet_V2_L_Weights\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from torchvision.models.vgg import VGG16_Weights, VGG19_Weights\n",
    "from torchvision.models.squeezenet import SqueezeNet1_1_Weights\n",
    "\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T15:44:43.212878428Z",
     "start_time": "2023-05-15T15:44:08.936689799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "\n",
    "def vgg_face_dag(weights_path='/home/disi/Project-IML/vgg_face_dag.pth', **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T15:46:21.022069192Z",
     "start_time": "2023-05-15T15:46:21.010561415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class LaBocciaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaBocciaModel, self).__init__()\n",
    "        #self.pretrained = squeezenet1_1(weights = SqueezeNet1_1_Weights.DEFAULT)\n",
    "        #self.pretrained = resnet50(weights = ResNet50_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg16(weights = VGG16_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg19(weights = VGG19_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = resnet18(weights = ResNet18_Weights.DEFAULT).eval()\n",
    "        self.pretrained = efficientnet_v2_l(weights = EfficientNet_V2_L_Weights.DEFAULT).eval()\n",
    "        self.pretrained.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T13:39:27.239419822Z",
     "start_time": "2023-05-15T13:39:27.238118599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 13:39:48.936109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 13:39:57.453217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from deepface.commons import functions\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/query/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    detection = functions.extract_faces(img = img, enforce_detection=False)\n",
    "    x, y, w, h = detection[0][1].values()\n",
    "    aligned_img = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    aligned_img = cv2.cvtColor(aligned_img, cv2.COLOR_BGRA2RGB)\n",
    "    aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "    cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    detection = functions.extract_faces(img = img, enforce_detection=False)\n",
    "    x, y, w, h = detection[0][1].values()\n",
    "    aligned_img = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    aligned_img = cv2.cvtColor(aligned_img, cv2.COLOR_BGRA2RGB)\n",
    "    aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "    cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T13:40:17.964967614Z",
     "start_time": "2023-05-15T13:39:34.177352016Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = LaBocciaModel()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for path in gallery_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    #image = cv2.normalize(np.asarray(image), None, 0, 1.0, cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    #image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160), antialias=True)(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5,0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    embeddings[path] = model(image).detach().cpu().numpy()\n",
    "\n",
    "# save embeddings to disk\n",
    "with open(\"/home/disi/Project-IML/embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "queries = {}\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "for query in query_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, query))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    #image = cv2.normalize(np.asarray(image), None, 0, 1.0, cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    #image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160), antialias=True)(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    queries[query] = model(image).detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T13:43:16.048400422Z",
     "start_time": "2023-05-15T13:40:45.291959231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = vgg_face_dag()\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for path in gallery_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    #image = cv2.normalize(np.asarray(image), None, 0, 1.0, cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    #image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((224, 224), antialias=True)(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5,0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    embeddings[path] = model(image).detach().cpu().numpy()\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "queries = {}\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "for query in query_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, query))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    #image = cv2.normalize(np.asarray(image), None, 0, 1.0, cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    #image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((224, 224), antialias=True)(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    queries[query] = model(image).detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T15:54:39.494030337Z",
     "start_time": "2023-05-15T15:54:32.911267978Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw accuracy top 10 euclidian distance: 0.7358490566037736\n",
      "Raw accuracy top 5 euclidian distance: 0.7\n",
      "Raw accuracy top 1 euclidian distance: 1.0\n",
      "Raw accuracy top 10 cosine similarity: 0.7735849056603773\n",
      "Raw accuracy top 5 cosine similarity: 0.74\n",
      "Raw accuracy top 1 cosine similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "def extract_id(string):\n",
    "    splitter = string.split('/')\n",
    "    splitter = splitter[-1].split('_')\n",
    "    splitter = splitter[0]\n",
    "\n",
    "    return splitter\n",
    "\n",
    "def number_equal(sort):\n",
    "    query_num = 0\n",
    "\n",
    "    for i in sort:\n",
    "        i_id = extract_id(i[0])\n",
    "        if i_id == query_id:\n",
    "            query_num += 1\n",
    "\n",
    "    return query_num\n",
    "\n",
    "query_num_list_10 = []\n",
    "query_num_list_5 = []\n",
    "query_num_list_1 = []\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    counter = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "\n",
    "        gallery_id = extract_id(gallery)\n",
    "        if gallery_id in counter:\n",
    "            counter[gallery_id] += 1\n",
    "        else:\n",
    "            counter[gallery_id] = 1\n",
    "\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "    #print(f\"Query: {query}\")\n",
    "    #print(sorted_distances[:5])\n",
    "    sorted_distances_10 = sorted_distances[:10]\n",
    "    sorted_distances_5 = sorted_distances[:5]\n",
    "    sorted_distances_1 = sorted_distances[:1]\n",
    "\n",
    "    query_id = extract_id(query)\n",
    "\n",
    "    query_num_10 = number_equal(sorted_distances_10)\n",
    "    query_num_5 = number_equal(sorted_distances_5)\n",
    "    query_num_1 = number_equal(sorted_distances_1)\n",
    "\n",
    "    query_num_list_10.append(query_num_10)\n",
    "    query_num_list_5.append(query_num_5)\n",
    "    query_num_list_1.append(query_num_1)\n",
    "    #print(f'Gallery: {counter[query_id]}, found: {query_num}')\n",
    "\n",
    "print(f'Raw accuracy top 10 euclidian distance: {np.array(query_num_list_10).mean()/np.array(list(counter.values())).mean()}')\n",
    "print(f'Raw accuracy top 5 euclidian distance: {np.array(query_num_list_5).mean()/min(np.array(list(counter.values())).mean(),5)}')\n",
    "print(f'Raw accuracy top 1 euclidian distance: {np.array(query_num_list_1).mean()/min(np.array(list(counter.values())).mean(),1)}')\n",
    "\n",
    "# now again but with another distance metric\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "query_num_list_10 = []\n",
    "query_num_5 = []\n",
    "query_num_1 = []\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"Query: {query}\")\n",
    "    #print(sorted_distances[:5])\n",
    "\n",
    "    sorted_distances_10 = sorted_distances[:10]\n",
    "    sorted_distances_5 = sorted_distances[:5]\n",
    "    sorted_distances_1 = sorted_distances[:1]\n",
    "\n",
    "    query_id = extract_id(query)\n",
    "\n",
    "    query_num_10 = number_equal(sorted_distances_10)\n",
    "    query_num_5 = number_equal(sorted_distances_5)\n",
    "    query_num_1 = number_equal(sorted_distances_1)\n",
    "\n",
    "    query_num_list_10.append(query_num_10)\n",
    "    query_num_list_5.append(query_num_5)\n",
    "    query_num_list_1.append(query_num_1)\n",
    "    #print(f'Gallery: {counter[query_id]}, found: {query_num}')\n",
    "\n",
    "print(f'Raw accuracy top 10 cosine similarity: {np.array(query_num_list_10).mean()/np.array(list(counter.values())).mean()}')\n",
    "print(f'Raw accuracy top 5 cosine similarity: {np.array(query_num_list_5).mean()/min(np.array(list(counter.values())).mean(),5)}')\n",
    "print(f'Raw accuracy top 1 cosine similarity: {np.array(query_num_list_1).mean()/min(np.array(list(counter.values())).mean(),1)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T15:55:02.023888304Z",
     "start_time": "2023-05-15T15:54:50.486232124Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VGGFace pretrained\n",
    "Raw accuracy top 10 euclidian distance: 0.7358490566037736\n",
    "Raw accuracy top 5 euclidian distance: 0.7\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.7735849056603773\n",
    "Raw accuracy top 5 cosine similarity: 0.74\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "\n",
    "EfficientNet:\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.5943396226415094\n",
    "Raw accuracy top 5 euclidian distance: 0.51\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.6603773584905661\n",
    "Raw accuracy top 5 cosine similarity: 0.52\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "VGG19\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.37735849056603776\n",
    "Raw accuracy top 5 euclidian distance: 0.26\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.44339622641509435\n",
    "Raw accuracy top 5 cosine similarity: 0.27999999999999997\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "Resnet50\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.4716981132075472\n",
    "Raw accuracy top 5 euclidian distance: 0.35\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.4905660377358491\n",
    "Raw accuracy top 5 cosine similarity: 0.37\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "VGG16\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.38679245283018865\n",
    "Raw accuracy top 5 euclidian distance: 0.29\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.37735849056603776\n",
    "Raw accuracy top 5 cosine similarity: 0.29500000000000004\n",
    "Raw accuracy top 1 cosine similarity: 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterate over the queries\n",
    "# set the number of retrieved images to display\n",
    "num_retrievals = 5\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "\n",
    "    # sort the distances in descending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_similarities = [x[1]*100 for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their distances\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"Similarity: {top_similarities[i]:.2f}%\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# set the number of retrieved images to display\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "\n",
    "    # sort the distances in ascending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_distances = [x[1] for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their similarities\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"EuclidianD: {top_distances[i]:.2f}%\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cosine_similarity function returns a matrix of pairwise cosine similarities between the query embedding and the gallery embeddings. Since we are comparing one query image with multiple gallery images, we need to take the first element of the first dimension to get a single similarity score. Also, note that we pass reverse=True to sorted function to sort the distances in descending order since cosine similarity values range between -1 and 1, with higher values indicating more similarity."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
