{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 12:56:20.624668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 12:56:21.579946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, resnet18, squeezenet1_1\n",
    "from torchvision.models.resnet import ResNet50_Weights, ResNet18_Weights\n",
    "from torchvision.models import efficientnet_v2_l\n",
    "from torchvision.models.efficientnet import EfficientNet_V2_L_Weights\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from torchvision.models.vgg import VGG16_Weights, VGG19_Weights\n",
    "from torchvision.models.squeezenet import SqueezeNet1_1_Weights\n",
    "\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T12:56:22.673867340Z",
     "start_time": "2023-05-28T12:56:18.438148095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "\n",
    "def vgg_face_dag(weights_path='/home/disi/Project-IML/vgg_face_dag.pth'):\n",
    "\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T12:56:22.701244433Z",
     "start_time": "2023-05-28T12:56:22.680823591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class LaBocciaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaBocciaModel, self).__init__()\n",
    "        #self.pretrained = squeezenet1_1(weights = SqueezeNet1_1_Weights.DEFAULT)\n",
    "        #self.pretrained = resnet50(weights = ResNet50_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg16(weights = VGG16_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg19(weights = VGG19_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = resnet18(weights = ResNet18_Weights.DEFAULT).eval()\n",
    "        self.pretrained = efficientnet_v2_l(weights = EfficientNet_V2_L_Weights.DEFAULT).eval()\n",
    "        self.pretrained.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T13:39:27.239419822Z",
     "start_time": "2023-05-15T13:39:27.238118599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing training data..\n",
      "==> Epoch: 1\n",
      "(512, 2622)\n",
      "torch.Size([512])\n",
      "torch.Size([512, 3, 224, 224])\n",
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m eta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m     37\u001B[0m save \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/disi/Project-IML/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 38\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtestloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minner_param\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhlen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/jupyterfold/train_functions.py:55\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, net, device, trainloader, testloader, classes, scheduler, lr, inner_param, sigma, hlen, eta, save)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(imgs\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(device)\n\u001B[0;32m---> 55\u001B[0m loss_dual \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhash_bits\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m hash_binary \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msign(hash_bits)\n\u001B[1;32m     57\u001B[0m batchY \u001B[38;5;241m=\u001B[39m EncodingOnehot(labels, classes)\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/.virtualenvs/Project-IML/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/jupyterfold/train_functions.py:124\u001B[0m, in \u001B[0;36mDualClasswiseLoss.forward\u001B[0;34m(self, x, labels)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;66;03m#   compute L_1 with single constraint.\u001B[39;00m\n\u001B[1;32m    123\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 124\u001B[0m distmat \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m          \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcenters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m distmat\u001B[38;5;241m.\u001B[39maddmm_(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcenters\u001B[38;5;241m.\u001B[39mt(), beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    127\u001B[0m dist_div \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigma\u001B[38;5;241m*\u001B[39mdistmat)\u001B[38;5;241m/\u001B[39m(torch\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigma\u001B[38;5;241m*\u001B[39mdistmat)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-6\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets\n",
    "from train_functions import *\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "train_path = \"/run/user/1000/train_dataset/\"\n",
    "test_path = \"/run/user/1000/test_dataset/\"\n",
    "\n",
    "\n",
    "t = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Resize((224, 224), antialias=True),\n",
    "            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = datasets.ImageFolder(root=train_path, transform=t)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testset = datasets.ImageFolder(root=test_path, transform=t)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "classes = len(trainset.classes)\n",
    "net = Vgg_face_dag()\n",
    "scheduler = adjust_lr(50, 0.1)\n",
    "lr = 0.005\n",
    "epochs = 10\n",
    "inner_param = 0.5\n",
    "sigma = 0.25\n",
    "hlen = 48\n",
    "eta = 0.01\n",
    "save = \"/home/disi/Project-IML/\"\n",
    "train(epochs, net, device, trainloader, testloader, classes, scheduler, lr, inner_param, sigma, hlen, eta, save)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T12:57:25.134928984Z",
     "start_time": "2023-05-28T12:56:22.697207222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 15:37:38.488311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 15:37:45.209611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = \"/home/disi/Project-IML/query/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "tools.face_alignment(input_dir, output_dir)\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "\n",
    "tools.face_alignment(input_dir, output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T15:54:34.416381388Z",
     "start_time": "2023-05-16T15:37:14.033558655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, root: str):\n",
    "\n",
    "    self.root = root\n",
    "\n",
    "    #self.split_ids = io.loadmat(os.path.join(root, \"setid.mat\"))\n",
    "    #self.labels = io.loadmat(os.path.join(root, \"imagelabels.mat\"))[\"labels\"][0]\n",
    "    self.split_ids = {}\n",
    "    self.image_paths = sorted(glob.glob(os.path.join(self.root, \"jpg\", \"*.jpg\")))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_paths)\n",
    "\n",
    "  def __getitem__(self, idx: int):\n",
    "\n",
    "    label = self.labels[idx]\n",
    "    img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "\n",
    "    return img, label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# PER LA BOCCIA\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = LaBocciaModel()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = tools.embeddings_calc(gallery_paths, model, device, data_dir)\n",
    "\n",
    "\n",
    "# save embeddings to disk\n",
    "with open(\"/home/disi/Project-IML/embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "queries = tools.embeddings_calc(query_paths, model, device, data_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T13:43:16.048400422Z",
     "start_time": "2023-05-15T13:40:45.291959231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## PER VGG FACE DAG\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = vgg_face_dag()\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = tools.embeddings_calc(gallery_paths, model, device, data_dir)\n",
    "\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "queries = tools.embeddings_calc(query_paths, model, device, data_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T16:04:20.901553528Z",
     "start_time": "2023-05-16T15:54:34.452947329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw accuracy top 10 euclidian distance: 0.1836694418335502\n",
      "Raw accuracy top 5 euclidian distance: 0.4298850574712644\n",
      "Raw accuracy top 1 euclidian distance: 0.5402298850574713\n",
      "Raw accuracy top 10 cosine similarity: 0.21036188666749175\n",
      "Raw accuracy top 5 cosine similarity: 0.45632183908045976\n",
      "Raw accuracy top 1 cosine similarity: 0.5977011494252874\n"
     ]
    }
   ],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "def extract_id(string):\n",
    "    splitter = string.split('/')\n",
    "    splitter = splitter[-1].split('_')\n",
    "    splitter = splitter[0]\n",
    "\n",
    "    return splitter\n",
    "\n",
    "def number_equal(sort):\n",
    "    query_num = 0\n",
    "\n",
    "    for i in sort:\n",
    "        i_id = extract_id(i[0])\n",
    "        if i_id == query_id:\n",
    "            query_num += 1\n",
    "\n",
    "    return query_num\n",
    "\n",
    "query_num_list_10 = []\n",
    "query_num_list_5 = []\n",
    "query_num_list_1 = []\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    counter = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "\n",
    "        gallery_id = extract_id(gallery)\n",
    "        if gallery_id in counter:\n",
    "            counter[gallery_id] += 1\n",
    "        else:\n",
    "            counter[gallery_id] = 1\n",
    "\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "    #print(f\"Query: {query}\")\n",
    "    #print(sorted_distances[:5])\n",
    "    sorted_distances_10 = sorted_distances[:10]\n",
    "    sorted_distances_5 = sorted_distances[:5]\n",
    "    sorted_distances_1 = sorted_distances[:1]\n",
    "\n",
    "    query_id = extract_id(query)\n",
    "\n",
    "    query_num_10 = number_equal(sorted_distances_10)\n",
    "    query_num_5 = number_equal(sorted_distances_5)\n",
    "    query_num_1 = number_equal(sorted_distances_1)\n",
    "\n",
    "    query_num_list_10.append(query_num_10)\n",
    "    query_num_list_5.append(query_num_5)\n",
    "    query_num_list_1.append(query_num_1)\n",
    "    #print(f'Gallery: {counter[query_id]}, found: {query_num}')\n",
    "\n",
    "print(f'Raw accuracy top 10 euclidian distance: {np.array(query_num_list_10).mean()/np.array(list(counter.values())).mean()}')\n",
    "print(f'Raw accuracy top 5 euclidian distance: {np.array(query_num_list_5).mean()/min(np.array(list(counter.values())).mean(),5)}')\n",
    "print(f'Raw accuracy top 1 euclidian distance: {np.array(query_num_list_1).mean()/min(np.array(list(counter.values())).mean(),1)}')\n",
    "\n",
    "# now again but with another distance metric\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "query_num_list_10 = []\n",
    "query_num_5 = []\n",
    "query_num_1 = []\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"Query: {query}\")\n",
    "    #print(sorted_distances[:5])\n",
    "\n",
    "    sorted_distances_10 = sorted_distances[:10]\n",
    "    sorted_distances_5 = sorted_distances[:5]\n",
    "    sorted_distances_1 = sorted_distances[:1]\n",
    "\n",
    "    query_id = extract_id(query)\n",
    "\n",
    "    query_num_10 = number_equal(sorted_distances_10)\n",
    "    query_num_5 = number_equal(sorted_distances_5)\n",
    "    query_num_1 = number_equal(sorted_distances_1)\n",
    "\n",
    "    query_num_list_10.append(query_num_10)\n",
    "    query_num_list_5.append(query_num_5)\n",
    "    query_num_list_1.append(query_num_1)\n",
    "    #print(f'Gallery: {counter[query_id]}, found: {query_num}')\n",
    "\n",
    "print(f'Raw accuracy top 10 cosine similarity: {np.array(query_num_list_10).mean()/np.array(list(counter.values())).mean()}')\n",
    "print(f'Raw accuracy top 5 cosine similarity: {np.array(query_num_list_5).mean()/min(np.array(list(counter.values())).mean(),5)}')\n",
    "print(f'Raw accuracy top 1 cosine similarity: {np.array(query_num_list_1).mean()/min(np.array(list(counter.values())).mean(),1)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T16:09:50.701199007Z",
     "start_time": "2023-05-16T16:04:20.941595220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VGGFace pretrained:\n",
    "Raw accuracy top 10 euclidian distance: 0.7358490566037736\n",
    "Raw accuracy top 5 euclidian distance: 0.7\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.7735849056603773\n",
    "Raw accuracy top 5 cosine similarity: 0.74\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "\n",
    "EfficientNet:\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.5943396226415094\n",
    "Raw accuracy top 5 euclidian distance: 0.51\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.6603773584905661\n",
    "Raw accuracy top 5 cosine similarity: 0.52\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "VGG19\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.37735849056603776\n",
    "Raw accuracy top 5 euclidian distance: 0.26\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.44339622641509435\n",
    "Raw accuracy top 5 cosine similarity: 0.27999999999999997\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "Resnet50\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.4716981132075472\n",
    "Raw accuracy top 5 euclidian distance: 0.35\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.4905660377358491\n",
    "Raw accuracy top 5 cosine similarity: 0.37\n",
    "Raw accuracy top 1 cosine similarity: 1.0\n",
    "\n",
    "VGG16\n",
    "\n",
    "Raw accuracy top 10 euclidian distance: 0.38679245283018865\n",
    "Raw accuracy top 5 euclidian distance: 0.29\n",
    "Raw accuracy top 1 euclidian distance: 1.0\n",
    "Raw accuracy top 10 cosine similarity: 0.37735849056603776\n",
    "Raw accuracy top 5 cosine similarity: 0.29500000000000004\n",
    "Raw accuracy top 1 cosine similarity: 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterate over the queries\n",
    "# set the number of retrieved images to display\n",
    "num_retrievals = 5\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "\n",
    "    # sort the distances in descending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_similarities = [x[1]*100 for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their distances\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"Similarity: {top_similarities[i]:.2f}%\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# set the number of retrieved images to display\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "\n",
    "    # sort the distances in ascending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_distances = [x[1] for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their similarities\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"EuclidianD: {top_distances[i]:.2f}%\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cosine_similarity function returns a matrix of pairwise cosine similarities between the query embedding and the gallery embeddings. Since we are comparing one query image with multiple gallery images, we need to take the first element of the first dimension to get a single similarity score. Also, note that we pass reverse=True to sorted function to sort the distances in descending order since cosine similarity values range between -1 and 1, with higher values indicating more similarity."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
