{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D6xpg7KF0tO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, resnet18, squeezenet1_1\n",
    "from torchvision.models.resnet import ResNet50_Weights, ResNet18_Weights\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from torchvision.models.vgg import VGG16_Weights, VGG19_Weights\n",
    "from torchvision.models.squeezenet import SqueezeNet1_1_Weights\n",
    "\n",
    "class DEFmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DEFmodel, self).__init__()\n",
    "        #self.pretrained = squeezenet1_1(weights = SqueezeNet1_1_Weights.DEFAULT)\n",
    "        #self.pretrained = resnet50(weights = ResNet50_Weights.DEFAULT)\n",
    "        #self.pretrained = vgg16(weights = VGG16_Weights.DEFAULT)\n",
    "        self.pretrained = vgg19(weights = VGG19_Weights.DEFAULT)\n",
    "        self.pretrained.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rWbk8XoF0tR"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = DEFmodel()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "\n",
    "for path in gallery_paths:\n",
    "    print(path)\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    embeddings[path] = model(image).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5z-lLkZ1C1e",
    "outputId": "cb7e606e-3e5a-48e4-84d4-42626344771f"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/disi/Project-IML/query/\"\n",
    "queries = {}\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "for query in query_paths:\n",
    "    print(query)\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    queries[query] = model(image).detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "    print(f\"Query: {query}\")\n",
    "    for i in range(5):\n",
    "        print(f\"Rank {i+1}: {sorted_distances[i][0]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "py79LRz7F0tR",
    "outputId": "f47a2d66-1ae0-4682-9025-ef1dfd8aa5a0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_alignment\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/query/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "## default margin = 0.05\n",
    "margin = 1\n",
    "\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False, device=\"cuda\")\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith('.jpg') or file_name.endswith('.png') or file_name.endswith('.jpeg'):\n",
    "        img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        preds = fa.get_landmarks(gray)\n",
    "        if preds is None:\n",
    "            continue\n",
    "        center = np.mean(preds[0], axis=0)\n",
    "        left_eye = preds[0][36]\n",
    "        right_eye = preds[0][45]\n",
    "        dY = right_eye[1] - left_eye[1]\n",
    "        dX = right_eye[0] - left_eye[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        M = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n",
    "        aligned_img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "        x, y, w, h = cv2.boundingRect(preds[0])\n",
    "        h_margin = int(h*margin*2) if y - h*margin*2 > 0 else int(h*margin)\n",
    "\n",
    "        ## debug ##\n",
    "        w_margin = int(w*margin*2) if x - w*margin*2 > 0 else int(w*margin)\n",
    "        aligned_img = aligned_img[y-h-int(h_margin):y+h+int(h_margin), x-w-int(w_margin):x+w+int(w_margin)]\n",
    "\n",
    "        ##\n",
    "        #aligned_img = aligned_img[y-int(h*margin):y+h+int(h*margin), x-int(w*margin):x+w+int(w*margin)]\n",
    "        #print(aligned_img.shape)\n",
    "        aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "        cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)\n",
    "\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith('.jpg') or file_name.endswith('.png') or file_name.endswith('.jpeg'):\n",
    "        img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        preds = fa.get_landmarks(gray)\n",
    "        if preds is None:\n",
    "            continue\n",
    "        if (len(preds) > 1):\n",
    "            print(\"More than one face detected in image: \", file_name)\n",
    "\n",
    "        center = np.mean(preds[0], axis=0)\n",
    "        left_eye = preds[0][36]\n",
    "        right_eye = preds[0][45]\n",
    "        dY = right_eye[1] - left_eye[1]\n",
    "        dX = right_eye[0] - left_eye[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        M = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n",
    "        aligned_img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "        x, y, w, h = cv2.boundingRect(preds[0])\n",
    "        aligned_img = aligned_img[y-h-int(h*margin):y+h+int(h*margin), x-w-int(w*margin):x+w+int(w*margin)]\n",
    "        try:\n",
    "          aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "        cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from deepface.commons import functions\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/query/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    detection = functions.extract_faces(img = img, enforce_detection=False)\n",
    "    x, y, w, h = detection[0][1].values()\n",
    "    aligned_img = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    aligned_img = cv2.cvtColor(aligned_img, cv2.COLOR_BGRA2RGB)\n",
    "    aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "    cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, file_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    detection = functions.extract_faces(img = img, enforce_detection=False)\n",
    "    detection = functions.extract_faces(img = img, enforce_detection=False)\n",
    "    x, y, w, h = detection[0][1].values()\n",
    "    aligned_img = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    aligned_img = cv2.cvtColor(aligned_img, cv2.COLOR_BGRA2RGB)\n",
    "    aligned_img = cv2.resize(aligned_img, (160, 160))\n",
    "    cv2.imwrite(os.path.join(output_dir, file_name), aligned_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jv1zxC4YF0tT",
    "outputId": "130455aa-2731-4c6e-9639-4a7537dea90a"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model = DEFmodel()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for path in gallery_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160))(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    embeddings[path] = model(image).detach().cpu().numpy()\n",
    "# save embeddings to disk\n",
    "import pickle\n",
    "with open(\"/home/disi/Project-IML/embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "queries = {}\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "for query in query_paths:\n",
    "    image = cv2.imread(os.path.join(data_dir, query))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    image =  torchvision.transforms.Resize((160, 160))(image)\n",
    "    image = torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    queries[query] = model(image).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LBJsGVmF0tV",
    "outputId": "53398225-4523-47f3-8e4b-e7e409bd6b4d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidian_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "    print(f\"Query: {query}\")\n",
    "    print(sorted_distances[:5])\n",
    "\n",
    "# now again but with another distance metric\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(sorted_distances[:5])\n",
    "    \n",
    "\n",
    "# set the number of retrieved images to display\n",
    "num_retrievals = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "eR3Ew3EgF0tV",
    "outputId": "fd8fda56-792f-4242-b95a-be100ac87fdb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# iterate over the queries\n",
    "# set the number of retrieved images to display\n",
    "num_retrievals = 5\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "\n",
    "    # sort the distances in descending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_similarities = [x[1]*100 for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their distances\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"Similarity: {top_similarities[i]:.2f}%\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# set the number of retrieved images to display\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = euclidian_distance(query_embedding, gallery_embedding)\n",
    "\n",
    "    # sort the distances in ascending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_distances = [x[1] for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their similarities\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"EuclidianD: {top_distances[i]:.2f}%\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBtgolUmF0tV"
   },
   "source": [
    "The cosine_similarity function returns a matrix of pairwise cosine similarities between the query embedding and the gallery embeddings. Since we are comparing one query image with multiple gallery images, we need to take the first element of the first dimension to get a single similarity score. Also, note that we pass reverse=True to sorted function to sort the distances in descending order since cosine similarity values range between -1 and 1, with higher values indicating more similarity."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
